{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e7b2925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73426043",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4.1-nano-2025-04-14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32d7718f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2774952e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"tell me a curious fact about {soccer_player}\")\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91d6bce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A fascinating fact about Cristiano Ronaldo is that he has a tattoo of his late father’s name, \"José Dinis Aveiro,\" on his left arm, symbolizing the deep bond they shared. Additionally, Ronaldo is known for his extraordinary dedication to fitness; at age 38, he was still performing at the highest levels, showcasing his remarkable longevity in professional football.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model | output_parser\n",
    "\n",
    "chain.invoke({\"soccer_player\": \"Ronaldo\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac824f3",
   "metadata": {},
   "source": [
    "## Use of .bind() to add arguments to a Runnable in a LCEL Chain\n",
    "* For example, we can add an argument to stop the model response when it reaches the word \"Ronaldo\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c5b36a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A curious fact about Cristiano '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model.bind(stop=[\"Ronaldo\"]) | output_parser\n",
    "chain.invoke({\"soccer_player\": \"Ronaldo\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e143185",
   "metadata": {},
   "source": [
    "# Combining LCEL Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab459c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4.1-nano-2025-04-14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a89ea9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a sentence about {politician}\")\n",
    "\n",
    "chain = prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67d0d729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Warming to his role as a prominent British statesman, Neville Chamberlain is best remembered for his policy of appeasement toward Nazi Germany prior to World War II.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke('Chamberlain')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd759d51",
   "metadata": {},
   "source": [
    "# Combined chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "962ac029",
   "metadata": {},
   "outputs": [],
   "source": [
    "historian_prompt = ChatPromptTemplate.from_template(\"Was {politician} positive for Humanity?\")\n",
    "\n",
    "composed_chain = {\"politician\": chain} | historian_prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55936a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, Abraham Lincoln is widely regarded as a positive and transformative figure for humanity. As the 16th President of the United States, he led the nation through its Civil War, preserving the Union, and took significant steps to abolish slavery with the issuance of the Emancipation Proclamation and his support for the 13th Amendment. His leadership helped to promote principles of equality, human rights, and national unity, making a lasting impact on the course of history and advancing the cause of justice and freedom.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "composed_chain.invoke({\"politician\": \"Lincoln\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdaa9e2",
   "metadata": {},
   "source": [
    "## Another example: a chain inside another chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3ea57ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "France is located in the continent of Europe.\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Be more specific in the first prompt\n",
    "prompt1 = ChatPromptTemplate.from_template(\n",
    "    \"What country was the politician {politician} from? Provide only the country name.\"\n",
    ")\n",
    "\n",
    "# Be more specific in the second prompt\n",
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"What continent is the country {country} in? Be specific and respond in {language}.\"\n",
    ")\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "chain1 = prompt1 | model | StrOutputParser()\n",
    "\n",
    "chain2 = (\n",
    "    {\"country\": chain1, \"language\": itemgetter(\"language\")}\n",
    "    | prompt2\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Try running it again\n",
    "result = chain2.invoke({\"politician\": \"Mitterrand\", \"language\": \"English\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefce08e",
   "metadata": {},
   "source": [
    "# LCEL chain at work in a typical RAG app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b783327",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4.1-nano-2025-04-14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "518bd21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "c:\\Users\\rbhar\\anaconda3\\envs\\llmapp_latest\\Lib\\site-packages\\langsmith\\client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bf4902d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task Decomposition involves breaking down a complex task into smaller, more manageable steps or subgoals. Techniques like Chain of Thought and Tree of Thoughts facilitate this by guiding the model to think step-by-step or explore multiple reasoning paths. External tools, such as classical planners using PDDL, can also be employed to handle long-horizon planning by translating problems into intermediate representations.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"What is Task Decomposition?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a12b8ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Self-reflection is a process that enables agents to evaluate and improve their actions by analyzing past experiences, correcting mistakes, and refining future decisions. It involves creating higher-level summaries or inferences from memories to guide behavior and enhance reasoning skills. This iterative mechanism helps agents perform better in complex or uncertain tasks.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"What is Self-Reflection?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67623e45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmapp_latest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
